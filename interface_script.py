# -*- coding: utf-8 -*-
"""interface_script.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15QqscBS3PbPAaur23wHR8ZTxNFWcZZke
"""

import argparse
import os
import glob
from PIL import Image
import numpy as np
import tensorflow as tf
import cv2

def preprocess_image(image_path):
    def remove_frame(image):
        # Convert the image to a numpy array
        image_np = np.array(image)

        # Convert to grayscale if the image is not grayscale
        if len(image_np.shape) == 3:
            image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2GRAY)

        # Threshold the image to binary using Otsu's method
        _, image_binary = cv2.threshold(image_np, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

        # Find contours in the binary image
        contours, _ = cv2.findContours(image_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # Get the bounding box of the largest contour
        largest_contour = max(contours, key=cv2.contourArea)
        x, y, w, h = cv2.boundingRect(largest_contour)

        # Use the bounding box to remove the frame
        image_np = image_np[y:y+h, x:x+w]

        # Convert the numpy array back to a PIL image
        image = Image.fromarray(image_np)

        return image


    # Load the image
    image = Image.open(image_path)

    # Remove white frame
    image = remove_frame(image)

    # Resize the image to 28x28 pixels
    image = image.resize((28, 28))

    # Convert the image to grayscale
    image = image.convert('L')

    # Flip the image horizontally
    image = image.transpose(Image.FLIP_LEFT_RIGHT)

    # Rotate the image 90 degrees anticlockwise
    image = image.rotate(90)

    # Convert the image data to a numpy array and normalize it
    image = np.array(image) / 255.0

    # Check if image is not in the format (28, 28), then reshape it
    if image.shape != (28, 28):
        image = image.reshape((28, 28))

    # Add an extra dimension for the batch size
    image_batch = np.expand_dims(image, axis=0)

    # Add an extra dimension for the color channel
    image_batch = np.expand_dims(image_batch, axis=-1)
    
    return image_batch

def main(directory):
    # Load model
    model = tf.keras.models.load_model('model.h5')

    # Create a mapping from indices to characters
    index_to_char = list('0123456789ABCDEFGHJKLMNPRSTUVWXYZ')

    # Find all images in the directory
    files = os.listdir(directory)

    # prepend the folder path to each file name
    image_paths = [os.path.join(directory, file) for file in files]
    
    print(f'Found images: {image_paths}')
    
    for image_path in image_paths:
        # Preprocess the image
        image_batch = preprocess_image(image_path)
        
        # Predict the class of the image
        predictions = model.predict(image_batch)
        
        # The output is a vector of probabilities for each class
        # To get the class with the highest probability, we can use argmax
        predicted_class_index = np.argmax(predictions)
        
        # Now you can use this mapping to get the predicted character
        predicted_class_label = index_to_char[predicted_class_index]

        # Print the result in CSV format
        print(f"{ord(predicted_class_label)}, {image_path}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Character recognition inference script.')
    parser.add_argument('--input', type=str, default='test_data', help='Path to the directory with image samples.')
    args = parser.parse_args()
    main(args.input)
